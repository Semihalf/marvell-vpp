
Below are instructions for reproducing a working VPP environment on top of Marvell's Armada-7/8K SoCs
The document below specifies the exact versions used for reproducing the system, however, different
versions of these software components might be used, although, this might require some slight modifications
to the installation process.

1. Hardware
-----------
 - Armada-7/8K development / community board.
   (For the purpose of this readme, a 8040-McBin board was used).
 - Traffic generator (connected through the 10G ports).
 - External network access (for github, packages installation...) - through
   port 2 of McBin board (eth2).

2. Basic board preps
---------------------
 - Boot the board using some temporary Kernel / DTB images (temporary, as it
   will be replaced with a new Kernel in section #3).
 - Use ubuntu-arm64 file-system (ubuntu-16.04 was used in our case).
 - The following packages will be required during the installation process:
   # apt-get install git openssh-server make bc
   # apt-get install autoconf automake libtool
   # apt-get install ccache
   # (optional) apt-get install xterm socat zip telnet

3. MUSDK (part 1)
-----------------
 - Clone MUSDK code from github
   # cd /root/
   # git clone https://github.com/MarvellEmbeddedProcessors/musdk-marvell.git -b musdk-armada-17.10 musdk-marvell

4. Kernel
---------
 - Clone Kernel code from github
   # cd /root/
   # git clone https://github.com/MarvellEmbeddedProcessors/linux-marvell.git -b linux-4.4.52-armada-17.10 linux-marvell
 - Apply musdk kernel patches:
   # cd linux-marvell
   # git am /root/musdk-marvell/patches/linux/*.patch
 - Configure and build the Kernel
   # make mvebu_v8_lsp_defconfig
   # make -j4 Image dtbs modules
   # make modules_install
   # make install
   # cp arch/arm64/boot/Image arch/arm64/boot/dts/marvell/armada-8040-mcbin.dtb /boot/
 -  Reboot the board using the Kernel and DTB compiled above.

5. MUSDK (part 2)
-----------------
 - Configure & build musdk libraries / applications
   # cd /root/musdk-marvell
   # export KDIR=/root/linux-marvell
   # ./bootstrap
   # ./configure --enable-shared --enable-bpool-dma=64 --enable-sam --prefix=/usr
   # make -j4
   # make install
 - Build & install MUSDK modules
   # cd modules/
   # for i in dmax2 neta pp2 sam uio; do cd $i; make; make -C $KDIR M=`pwd` modules_install; cd -; done

6. pp2-sysfs driver
-------------------
 - Clone mvpp2-sysfs source code from github
   # cd /root/
   # git clone https://github.com/MarvellEmbeddedProcessors/mvpp2x-marvell.git -b mvpp2x-armada-17.10 pp2_sysfs
 - Build and install
   # cd /root/pp2_sysfs/sysfs/
   # cp Makefile_sysfs Makefile
   # export KDIR=/root/linux-marvell
   # export KERNEL_SOURCES=1
   # make
   # make -C $KDIR M=`pwd` modules_install

7. DPDK (Extract Marvell patches only)
--------------------------------------
   The patches are boundled within the current repositiory.
   Updated this part of instruction after development.

8. VPP
------
 - Clone Marvell's VPP port
   # cd /root/
   ASDFASDFAS
   git clone https://github.com/Semihalf/marvell-vpp.git -b mrvl_on_master_19_03
 - Prepare build env
   # cd marvell-vpp/
   # export DPDK_VERSION=18.02
   # export AESNI=n
   # export LIBMUSDK_PATH=/usr/
   # make install-dep
   # make bootstrap
   # groupadd vpp
 - Build vpp:
   # make -j4 build-release
 - Create VPP configuration file
   # mkdir -p /etc/vpp/
   # cp src/scripts/mrvl/mrvl_demo_startup.conf /etc/vpp/startup.conf

Running simple bridging setup (between eth0 & eth1 on McBin board)
-----------------------------
 - Load kernel modules
   # modprobe -a musdk_uio mv_dmax2_uio mv_pp_uio mv_sam_uio mvpp2x_sysfs
   if IPsec is going to be tested
   # insmod /lib/modules/4.4.52-armada-17.10.3-g84fb82a/kernel/drivers/crypto/inside-secure/crypto_safexcel.ko rings=0,0
- Hugepages configuration
   # echo 1000 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages
 - Run VPP
   # cd /root/vpp/
   # export STARTUP_CONF=/etc/vpp/startup.conf
   # make run-release &
   # ifconfig eth0 up
   # ifconfig eth1 up
 - Connect to VPP CLI:
   # telnet 127.0.0.1 5002
 - (from CLI) create bridge, and associate 2 ports:
   # set interface state TenGigabitEthernet0 up
   # set interface state TenGigabitEthernet1 up
   # create bridge-domain 1
   # set interface l2 bridge TenGigabitEthernet0 1
   # set interface l2 bridge TenGigabitEthernet1 1



Running bridging inside VM (eth0->vm(eth0)->vm(eth1)->eth1)
-----------------------------
 - Load kernel modules
   # modprobe -a musdk_uio mv_dmax2_uio mv_pp_uio mv_sam_uio mvpp2x_sysfs
 - Hugepages configuration
   # echo 1000 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages
 - Run VPP
   # cd /root/vpp-marvell/
   # export STARTUP_CONF=/etc/vpp/startup.conf
   # make run-release &
   # ifconfig eth0 up
   # ifconfig eth1 up
 - Connect to VPP CLI:
   # telnet 127.0.0.1 5002
 - (from CLI) create vhost ports:
   # create vhost socket /tmp/sock1.sock server feature-mask 0xFF
   # create vhost socket /tmp/sock2.sock server feature-mask 0xFF
 - (from CLI) link up all ports:
   # set interface state TenGigabitEthernet0 up
   # set interface state TenGigabitEthernet1 up
   # set interface state VirtualEthernet0/0/0 up
   # set interface state VirtualEthernet0/0/1 up
 - setup the bridge domains:
   # set interface l2 bridge TenGigabitEthernet0  1
   # set interface l2 bridge VirtualEthernet0/0/0 1
   # set interface l2 bridge TenGigabitEthernet1  2
   # set interface l2 bridge VirtualEthernet0/0/1 2

 VPP is configured. Now we need to boot a VM to bridge between VirtualEthernet0/0/0 and VirtualEthernet0/0/1
 quit VPP using #quit and continue

 - VM environment setup
    - Install QEMU and screen
	# apt-get install qemu-system-aarch64 screen python

    - Prepare VM linux image
       # cd /root/linux-marvell
       # git am /root/ovs-marvell/linux-guest-patches/*
       # ./scripts/config -e VFIO_NOIOMMU
       # ./scripts/config -e VFIO_NOIOMMU
       # make -j6
       # cp arch/arm64/boot/Image /boot/Image-vm

    - Prepare ubuntu-16.04 file system image for the guest VM
       # dd if=/dev/zero of=/root/ubuntu-16.04-vm-fs.img bs=1M count=2000
       # mkfs.ext4 /root/ubuntu-16.04-vm-fs.img
       # mkdir /mnt/loop
       # mount /root/ubuntu-16.04-vm-fs.img /mnt/loop
       # cd /mnt/loop
       # tar -xf /root/ubuntu-16.04-arm64.tar
       # cp /root/dpdk-marvell /mnt/loop/root/.

    - Install packages for VM file system
       # chroot /mnt/loop
       # dhclient eth2
       # apt-get update
       # apt-get install build-essential pciutils

    - Compile DPDK for VM
      - Disable KNI and MRVL PMD in config file
         - open config/common_linuxapp and delete CONFIG_RTE_KNI_KMOD
         - open config/common_base and delete
	    - CONFIG_RTE_LIBRTE_MRVL_PMD
	    - CONFIG_RTE_LIBRTE_MRVL_DEBUG
	    - CONFIG_RTE_MRVL_MUSDK_DMA_MEMSIZE
	    - CONFIG_RTE_LIBRTE_PMD_MRVL_CRYPTO
	    - CONFIG_RTE_LIBRTE_PMD_MRVL_CRYPTO_DEBUG
      - Build DPDK
	 # make config T=arm64-armv8a-linuxapp-gcc
	 # make
	 # make install

   10.5 Boot the VM
      - Start screen application and create a 2nd terminal
	   # screen
           # Ctrl-a c   " open 2nd terminal "
	   # Ctrl-a 1   " switch to 2nd terminal"
      - Boot VM with QEMU
	   # qemu-system-aarch64 -enable-kvm -nographic -kernel /boot/Image-vm -m 768 -M virt,iommu=on -cpu host -smp 2\
	        -drive file=/root/ubuntu-16.04-vm-fs.img,id=fs,if=none,format=raw -device virtio-blk-device,drive=fs \
	        -chardev socket,id=char0,path=/tmp/sock1.sock \
	        -netdev type=vhost-user,id=net0,chardev=char0,vhostforce  \
	        -device virtio-net-pci,mac=00:00:00:00:00:10,netdev=net0 \
	        -chardev socket,id=char1,path=/tmp/sock2.sock \
	        -netdev type=vhost-user,id=net1,chardev=char1,vhostforce \
	        -device virtio-net-pci,mac=00:00:00:00:00:11,netdev=net1 \
	        -object memory-backend-file,share=on,id=mem,size=768M,mem-path=/dev/hugepages \
	        -numa node,memdev=mem -mem-prealloc \
	        -append "earlyprintk console=ttyAMA0 isolcpus=1 rootwait root=/dev/vda rw"

       - Verify Virtio PCI devices exist. lspci should show
		00:00.0 Host bridge: Red Hat, Inc. Device 0008
		00:01.0 Ethernet controller: Red Hat, Inc Virtio network device
		00:02.0 Ethernet controller: Red Hat, Inc Virtio network device

    10.6 Run DPDK on VM
       - system setup
          # init s  /*  to eliminate un-needed processes from ubuntu */
	  # echo 1024 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages
          # mkdir /mnt/huge
          # mount -t hugetlbfs nodev /mnt/huge
          # echo 1 > /sys/module/vfio/parameters/enable_unsafe_noiommu_mode
          # dpdk-devbind -b vfio-pci 0000:00:01.0
          # dpdk-devbind -b vfio-pci 0000:00:02.0

       - dpdk run
          # testpmd -c 0x3 -- -i -a --total-num-mbufs=16384

     The system is now ready to bridge traffic.
     Back on the hypervisor, check that you have 2 threads occupying 100% CPU.
     Make sure none of these threads is running on CPU-0. If one of them does,
     move it to CPUs 1,2, or 3 using taskset.

9. Troubleshooting
---------------------
The issues will be described here to possibly save time of future developers:

Current:
    1) VPP crashes if you add non existent SA to a SPD, this is
       an issue of VPP (probably)
    2) VPP is unable to bind MRVL crypto driver, as the capabilities do not
       match - MRVL crypto driver is as of now, not able to truncate the
       digest. This results in (silent) error on SA creation, and likely
       leads to the crash described in 1)
    3) "[ERROR] Dma object already exits. " - this appears at startup,
       what is it, does it harm us?
    4) Sometimes the interface TX stays down for unknown reasons,
       then sometimes it starts working out of the blue, other
       times it requires to reboot the board (this always helps)
    5) If more than one worker thread is used, it is required to
       change the socket-mem parameter in startup.conf, other wise
       application will crash due to insufficient memory


Other issues which have been solved by changing the base,
if the baseline is going to change, watch out for those:
    1) In 03.2018 there have been some changes in how the
       IOVA table is filled, VPP did not work before that
       changes due to IOMMU misconfiguration or something.
       The packets were received, the pointer to pkt
       data pointed to a place in memory which only had `0`
       in it.
       I believe this commit made it work:
            https://gerrit.fd.io/r/#/c/11063/
       but I am not entirely sure.
    2) VPP tried to get the stats of a port before initializing it
       Changes to if it were upstreamed:
            https://gerrit.fd.io/r/#/c/11144/


